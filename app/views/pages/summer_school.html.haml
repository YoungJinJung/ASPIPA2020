
%h1 APSIPA Summer School 2020

-#%p
-#%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'workshop-mast'}
-#%div{id: 'workshop-mast', class: 'panel-collapse collapse'}
-#  %div{class: 'panel-body'}
%h4 Venue： The University of Auckland, New Zealand
%h4{class: 'specsess-heading'} Date: 2020/12/11

%br
%h3{class: 'specsess-heading'}Outline
%p An important mission of APSIPA ASC is to promote the education on signal and information technologies in the local region, and attract more students to join this promising research area. Therefore, we propose to organize a one-day summer school during APSIPA 2010 ASC in Auckland, New Zealand. This summer school will be a satellite event of the main conference, and just one day before the tutorial day, i.e., Dec. 11, 2020. In this summer school, we are going to provide a lecture titled “Data Driven Based Multimedia Technologies” on the five topics; Image and Volumetric Data Restoration, Image and video super-resolution, Intelligent Visual Editing, Bridging Images and Natural Language and Computer Graphics.


-#%p One of the major research challenges in this area is that at the core of reliable analytics lie reliable algorithms. These algorithms must be robust under a diverse set of synthesized yet seemingly realistic background conditions. Depending on the type of media, these conditions could manifest themselves in the audio or video channels and could even vary within the duration of the content, thereby making it challenging to apply off-the-shelf techniques from other domains. Analysis of such content necessitates the design and training of customized algorithms that seek to exploit specific properties of or additional structure in the data. Infact, for most vision or audio related tasks, produced media data proves to be one of the most difficult benchmarks. This issue is further compounded by absence of any large in-domain datasets with reliable annotations.

%p The features of APSIPA SS 2020 are as follows:

%table{class: 'table table-bordered'}
  %tr
    %td
      %b Theme
    %td
      Data Driven Based Multimedia Technologies
  %tr
    %td
      %b Date
    %td
      2020/12/11

  %tr
    %td
      %b Venue
    %td
      The University of Auckland, New Zealand
  %tr
    %td
      %b Speakers
    %td
      5 Scholars who attend APSIPA 2020, especially distinguished lectures in image and video research.

  %tr
    %td
      %b Main audience
    %td
      Colleague students, young researchers from universities in the local area.
  %tr
    %td
      %b Extra audience
    %td
      Colleague students from other areas to attend APSIPA ASC 2020

  %tr
    %td
      %b Lecture style
    %td
      Dealing with basic technology to applications for each session to have AI technology vision to colleague students and young researchers.

%br
%h3{class: 'specsess-heading'} Organizers
%p <b> Prof. Woon Seng Gan (NTU):</b> APSIPA BOG member, education VP. In charge of resource allocation, program design, publicity
%p <b>Prof. Sanghoon Lee (Yonsei University):</b> APSIPA BOG member, the Vice EiC of the APSIPA Newsletter, speaker invitation, program design, publicity

%br
%h3{class: 'specsess-heading'} Tentative program

%table{class: 'table table-bordered'}
  %tr
    %th{class: 'text-center'}  Speaker
    %th{class: 'text-center'}  Time
    %th{class: 'text-center'}  Action


  %tr
    %td{rowspan: 2} Shogo Muramatsu Niigata University, JAPAN
    %td{rowspan: 2}
      %b 12:00 - 12:50
      %b (10 minutes)
    %td{class: 'text-center'} <b>Lecture 1 :</b> Sparsity-Aware Image and Volumetric Data Restoration with Convolutional Dictionary Learning
  %tr
    %td{class: 'text-center'} <b>Q & A </b>


  %tr
    %td{rowspan: 2} Huihui Bai Beijing Jiaotong University, China
    %td{rowspan: 2}
      %b 13:00 - 13:50
      %b (10 minutes)
    %td{class: 'text-center'} <b>Lecture 2 :</b> Exploration of image and video super-resolution based on deep learning
  %tr
    %td{class: 'text-center'} <b>Q & A </b>


  %tr
    %td{rowspan: 2} Jiaying Liu Peking University, China
    %td{rowspan: 2}
      %b 14:00 - 14:50
      %b (10 minutes)
    %td{class: 'text-center'} <b>Lecture 3 :</b> Intelligent Visual Editing
  %tr
    %td{class: 'text-center'} <b>Q & A </b>

  %tr
    %td
    %td
      %b 15:00 – 15:30
    %td{class: 'text-center'} Coffee break


  %tr
    %td{rowspan: 2} Jianfei Cai Monash University, Australia
    %td{rowspan: 2}
      %b 15:30- 16:20
      %b (10 minutes)
    %td{class: 'text-center'} <b>Lecture 4 :</b> Bridging Images and Natural Language with Deep Learning
  %tr
    %td{class: 'text-center'} <b>Q & A </b>

  %tr
    %td{rowspan: 2} Sanghoon Lee, Yonsei University, Korea
    %td{rowspan: 2}
      %b 16:30- 17:20
      %b (10 minutes)
    %td{class: 'text-center'} <b>Lecture 5 :</b> Understanding, application and cognitive analysis of 3D imaging technology
  %tr
    %td{class: 'text-center'} <b>Q & A </b>




%br
%h3{class: 'specsess-heading'} Tentative title and summary :
%p Shogo Muramatsu Niigata University, JAPAN (APSIPA DL)
%p Jiaying Liu, Peking University, China (APSIPA IVM TC Member)
%p Huihui Bai, Beijing Jiaotong University, China (APSIPA DL)
%p Jianfei Cai, Monash University, Australia
%p Sanghoon Lee, Yonsei University, Korea (APSIPA BoG)

%br
%h3{class: 'specsess-heading'} Tentative speakers:
%p
  %b Lecturer: Shogo Muramatsu
%ul
  %li Tentative title :“Sparsity-Aware Image and Volumetric Data Restoration with Convolutional Dictionary Learning”
  %li Summary: In this lecture, sparsity-aware restoration process of images and volumetric data is outlined. First, the purpose and application examples of image and volumetric data restoration are introduced. Then, the relationship between simultaneous equations and signal restoration is illustrated. The following topics are also summarized: Inner products and filtering, linear systems and matrices, filter banks and synthesis dictionaries, sparse modeling and MAP estimation, image generation and prior knowledge. Convolutional dictionary learning is also explained in connection with the design of parametric filter banks. Finally, the nonlinear extension of convolution dictionary is discussed and compared with convolutional neural networks (CNNs).
  %li Bio: Shogo Muramatsu received the B.E., M.E. and Ph.D. degrees from Tokyo Metropolitan University, Tokyo, Japan, in 1993, 1995 and 1998, respectively. From 1997 to 1999, he worked at Tokyo Metropolitan University. In 1999, he joined Niigata University, where he is currently a Professor in the Faculty of Engineering. From 2003 to 2004, he was a Visiting Researcher at the University of Florence, Italy. His research interests include multidimensional signal processing, multi-rate systems, image and volumetric data restoration, video analysis, and embedded vision systems. Prof. Muramatsu is a Senior Member of IEEE and IEICE (Institute of Electronics, Information, and Communication Engineers of Japan) and a Member of APSIPA (Asia-Pacific Signal and Information Processing Association) and ITE (Institute of Image Information and Television Engineers of Japan). He served as an Area Editor of IEICE Transactions of Electronics, Communications and Computer Sciences from 2017 to 2019. He is currently an Associate Editor of the IEEE Transactions on Signal Processing and an APSIPA Distinguished Lecturer.
%br
%p
  %b Lecturer: Huihui Bai
%ul
  %li Tentative title: Exploration of image and video super-resolution based on deep learning
  %li Summary: With the development of various image sensors, there is a strong demand for image and video super-resolution, and the performance improvement of traditional super-resolution methods has encountered bottlenecks. In recent years, deep learning has made breakthroughs in the field of computer vision and image processing, which inspired us to explore the technology of image and video super resolution based on deep learning, in order to further improve the quality of reconstruction. In this report, I will focus on the recent research works of our research group on fast and accurate image and video super-resolution based on deep learning.
  %li Bio: Huihui Bai received her B.S. degree and her Ph.D. degree from Beijing Jiaotong University in 2001 and 2008, respectively. She is currently a professor in Institute of Information Science in Beijing Jiaotong University. Her research interests are image/video processing, image/ video coding and transmission. She has published over 80 journal and conference publications, one U.S. granted patent, one Australian innovation patent, 8 national invention patents. She has hosted many scientific research projects, such as Natural Science Foundation of China, Natural Science Foundation of Beijing and Natural Science Foundation of Jiangsu. Furthermore, she received Beijing science and technology achievement award (first class, second author), Shanxi science and technology achievement award (third class, fourth author) and Shanxi higher education science and technology achievement award (first class, fourth author). Additionally, she was selected as one of Beijing higher education young elite teacher project, star track of MSRA and creative fund from CCF and Tencent.

%br
%p
  %b Lecturer: Jiaying Liu
%ul
  %li Tentative title : Intelligent Visual Editing
  %li Summary: Intelligent image/video editing is a fundamental topic in image processing which has witnessed rapid progress in the last two decades. Due to various degradations in the image and video capturing, transmission and storage, image and video include many undesirable effects, such as low resolution, low light condition, rain streak and rain drop occlusions. The recovery of these degradations is ill-posed. With the wealth of statistic-based methods and learning-based methods, this problem can be unified into the cross-domain transfer, which cover more tasks, such as image stylization. In this talk, I will discuss recent progresses of visual editing. This talk covers both traditional statistics based and deep-learning based methods, and contains both biological-driven model, i.e. Retinex model, and data-driven model.
  %li Bio: Jiaying Liu is currently an Associate Professor with the Wangxuan Institute of Computer Technology, Peking University. She received the Ph.D. degree (Hons.) in computer science from Peking University, Beijing China, 2010. She has authored over 100 technical articles in refereed journals and proceedings, and holds 42 granted patents. Her current research interests include multimedia signal processing, compression, and computer vision. Dr. Liu is a Senior Member of IEEE, CSIG and CCF. She was a Visiting Scholar with the University of Southern California, Los Angeles, from 2007 to 2008. She was a Visiting Researcher with the Microsoft Research Asia in 2015 supported by the Star Track Young Faculties Award. She has served as a member of Membership Services Committee in IEEE Signal Processing Society, a member of Multimedia Systems & Applications (MSA) Technical Committee, Visual Signal Processing and Communications (VSPC) Technical Committee in IEEE Circuits and Systems Society, a member of the Image, Video, and Multimedia (IVM) Technical Committee in APSIPA. She has also served as the Associate Editor of IEEE Trans. on Image Processing, and Elsevier JVCI, the Technical Program Chair of IEEE VCIP-2019/ACM ICMR-2021, the Publicity Chair of IEEE ICME-2020/ICIP-2019, and the Area Chair of CVPR-2021/ECCV-2020/ICCV-2019. She was the APSIPA Distinguished Lecturer (2016-2017). In addition, Dr. Liu also devotes herself to teaching. She has run MOOC Programming Courses via Coursera/edX/ChineseMOOCs, which have been enrolled by more than 60 thousand students. She is also the organizer of the first Chinese MOOC Specialization in Computer Science. She is the youngest recipient of Peking University Outstanding Teaching Award.

%br
%p
  %b Lecturer: Jianfei Cai
%ul
  %li Tentative title : Bridging Images and Natural Language with Deep Learning
  %li Summary: As human beings, we can use our vision capabilities and language to perceive the world around us and to communicate with each other. While it seems to be easy for human beings to accomplish a wide variety of tasks that combine the two modalities, it is quite challenging for machines because it requires the model to understand both images and language, especially how they relate to each other. In this talk, I will discuss a series of our recent works to bridge images and natural language with deep learning, and to reduce the gap between the two modalities, including image captioning, scene graph based image captioning, cross-modal retrieval, etc. I will also touch the future directions along this line.
  %li Bio: Jianfei is a Professor at Faculty of IT, Monash University, where he currently serves as the Head for the Data Science & AI Department. Before that, he was a full professor, a cluster deputy director of Data Science & AI Research center (DSAIR), Head of Visual and Interactive Computing Division and Head of Computer Communications Division in Nanyang Technological University (NTU). His major research interests include visual computing, computer vision, and multimedia networking. He has published more than 200 technical papers in international conferences and journals. He is a co-recipient of paper awards in ACCV, ICCM, IEEE ICIP and MMSP. He has served as an Associate Editor for IEEE T-IP, T-MM, T-CSVT and Visual Computer as well as serving as Area Chair for ICCV, ECCV, ACM Multimedia, ICME and ICIP. He was the Chair of IEEE CAS VSPC-TC during 2016-2018. He had also served as the leading TPC Chair for IEEE ICME 2012.

%br
%p
  %b Lecturer: Sanghoon Lee
%ul
  %li Tentative title: Understanding, application and cognitive analysis of 3D imaging technology
  %li Summary: In this talk, I will introduce the unique advantages of using 3D images differently from that of using 2D images from the view of visual, technical and applications. During the talk, I will show examples of many contents using the 3D image approach and explain how effectively you can be interested in human cognitive perspective. Toward this, one of important technologies named 3D image reconstruction will be introduced, and its application and associated performance will be demonstrated. Such a technique requires a large amount of computation. To this end, using the power of data, deep running technology has been recently utilized to realize changing of light and material in two dimensions, which will be mentioned. It is difficult to deal with the technique of acquiring 3D human data, but artificial intelligence technology has evolved day by day, and nowadays, graphic technology and computer vision technology are fused to acquire human data. I will introduce this point on the lecture. In addition, I will present express emotions, wrinkles, etc. through a demonstration.
  %li Bio: Sanghoon Lee received the B.S. degree from Yonsei University, Seoul, South Korea, in 1989, the M.S. degree from the Korea Advanced Institute of Science and Technology, South Korea, in 1991, and the Ph.D. degree from The University of Texas at Austin, TX, USA, in 2000. From 1991 to 1996, he was with Korea Telecom, South Korea. From 1999 to 2002, he was with Lucent Technologies, NJ, USA. In 2003, he joined the EE Department, Yonsei University, as a Faculty Member, where he is currently a Full Professor. His current research interests include image/video processing, computer vision and graphics. Dr. Lee received the 2015 Yonsei Academic Award from Yonsei University, the 2012 Special Service Award from the IEEE Broadcast Technology Society, and the 2013 Special Service Award from the IEEE Signal Processing Society. He was the General Chair of the 2013 IEEE IVMSP Workshop, and has been served as steering committees for IEEE and APISPA conferences. He has been serving as the Chair of the IEEE P3333.1 Quality Assessment Working Group since 2011. He was the IVM Technical Committee Chair of APSIPA from 2018 to 2019, and is a Board of Governors Member of APSIPA in 2020. He was the IEEE IVMSP Technical Committee from 2014 to 2019, and has been the IEEE MMSP Technical Committee from 2016. He also served as an Editor of the JOURNAL OF COMMUNICATIONS AND NETWORKS from 2009 to 2015 and a special issue Guest Editor of the IEEE TRANSACTIONS ON IMAGE PROCESSING in 2013. He was an Associate Editor of the IEEE TRANSACTIONS ON IMAGE PROCESSING from 2010 to 2014. He served as an Associate Editor from 2014 to 2018, and currently a Senior Area Editor of the IEEE SIGNAL PROCESSING LETTERS.
